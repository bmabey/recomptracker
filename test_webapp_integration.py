#!/usr/bin/env python3
"""
Streamlit AppTest Integration Tests for DEXA Body Composition Analysis Web App

These tests use Streamlit's native AppTest framework to verify the webapp functionality
with the example config and various user interaction scenarios.

Test Coverage:
- Basic webapp loading and functionality (TestWebAppIntegration)
- Optional BF% goal integration and intelligent targeting (TestOptionalBFGoalIntegration) 
- Error handling scenarios (TestWebAppErrorHandling)

Run with: python -m pytest test_webapp_integration.py -v
Or with task runner: task test-webapp
Or run specific optional BF% tests: python run_optional_bf_tests.py
"""

import pytest
import streamlit.testing.v1 as testing
import json
import pandas as pd
from pathlib import Path


class TestWebAppIntegration:
    """Integration tests for the Streamlit webapp using AppTest framework."""
    
    @pytest.fixture
    def app(self):
        """Create AppTest instance for the webapp."""
        return testing.AppTest.from_file("webapp.py", default_timeout=10)
    
    def load_example_and_run_analysis(self, at):
        """Helper method to load example config and run analysis."""
        # Load example config
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        assert load_button is not None, "Load Example button should be present"
        load_button.click()
        at = at.run()
        
        # Run analysis
        analysis_button = None
        for button in at.button:
            if "ðŸ”¬ Run Analysis" in button.label:
                analysis_button = button
                break
        
        assert analysis_button is not None, "Run Analysis button should be present"
        analysis_button.click()
        at = at.run()
        
        return at
    
    @pytest.fixture
    def example_config_data(self):
        """Load example config data for testing."""
        with open("example_config.json", "r") as f:
            return json.load(f)
    
    def test_webapp_loads_successfully(self, app):
        """Test that the webapp loads without errors."""
        # Run the app
        at = app.run()
        
        # Verify basic UI elements are present
        assert len(at.title) > 0, "App title should be present"
        assert len(at.button) > 0, "Buttons should be present"
        
        # Verify no exceptions occurred
        assert len(at.exception) == 0, f"No exceptions should occur on load, found: {[e.value for e in at.exception]}"
    
    def test_load_example_config_button(self, app, example_config_data):
        """Test the 'Load Example' button functionality."""
        at = app.run()
        
        # Find and click the Load Example button
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        assert load_button is not None, "Load Example button should be present"
        
        # Click the button
        load_button.click()
        at = at.run()
        
        # Verify that user info is populated
        # Check that birth date input has the expected value (index 0)
        birth_date_input = at.text_input[0]
        assert birth_date_input.value == example_config_data["user_info"]["birth_date"], \
            f"Birth date should be {example_config_data['user_info']['birth_date']}"
        
        # Check gender selection (index 0)
        gender_selectbox = at.selectbox[0]
        assert gender_selectbox.value == example_config_data["user_info"]["gender"], \
            f"Gender should be {example_config_data['user_info']['gender']}"
        
        # Check height input (index 0)
        height_input = at.number_input[0]
        assert height_input.value == example_config_data["user_info"]["height_in"], \
            f"Height should be {example_config_data['user_info']['height_in']}"
    
    def test_analysis_execution_with_example_config(self, app):
        """Test that analysis runs successfully with example config data."""
        at = app.run()
        
        # Load example config
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        load_button.click()
        at = at.run()
        
        # Find and click the Run Analysis button
        analysis_button = None
        for button in at.button:
            if "ðŸ”¬ Run Analysis" in button.label:
                analysis_button = button
                break
        
        assert analysis_button is not None, "Run Analysis button should be present"
        
        # Click the analysis button
        analysis_button.click()
        at = at.run()
        
        # Verify no exceptions occurred during analysis
        assert len(at.exception) == 0, f"Analysis should complete without exceptions, found: {[e.value for e in at.exception]}"
        
        # Verify no error messages
        error_messages = [error.value for error in at.error]
        assert len(error_messages) == 0, f"No error messages should appear, found: {error_messages}"
    
    def test_analysis_results_display(self, app):
        """Test that analysis results are displayed correctly."""
        at = app.run()
        
        # Load example config and run analysis
        at = self.load_example_and_run_analysis(at)
        
        # Verify results section appears
        results_headers = [header.value for header in at.subheader]
        assert any("Analysis Results" in header for header in results_headers), \
            "Analysis Results section should be displayed"
        
        # Verify metric displays
        metrics = at.metric
        assert len(metrics) >= 4, "Should display at least 4 metrics (ALMI, ALMI %, FFMI, FFMI %)"
        
        # Check for specific metrics
        metric_labels = [metric.label for metric in metrics]
        expected_metrics = ["Current ALMI", "ALMI Percentile", "Current FFMI", "FFMI Percentile"]
        
        for expected_metric in expected_metrics:
            assert any(expected_metric in label for label in metric_labels), \
                f"Metric '{expected_metric}' should be displayed"
        
        # Verify metric values are reasonable
        for metric in metrics:
            if "ALMI" in metric.label and "kg/mÂ²" in metric.value:
                # ALMI should be between 5-15 kg/mÂ² for typical values
                almi_value = float(metric.value.split()[0])
                assert 5.0 <= almi_value <= 15.0, f"ALMI value {almi_value} should be reasonable"
            
            if "Percentile" in metric.label and "%" in metric.value:
                # Percentiles should be between 0-100%
                percentile = float(metric.value.replace("%", ""))
                assert 0.0 <= percentile <= 100.0, f"Percentile {percentile} should be valid"
    
    def test_plots_generation(self, app):
        """Test that both ALMI and FFMI plots are generated."""
        at = app.run()
        
        # Load example config and run analysis
        at = self.load_example_and_run_analysis(at)
        
        # Check for plot headers
        plot_headers = [header.value for header in at.subheader]
        assert any("ALMI Percentile Curves" in header for header in plot_headers), \
            "ALMI plot section should be displayed"
        assert any("FFMI Percentile Curves" in header for header in plot_headers), \
            "FFMI plot section should be displayed"
    
    def test_data_table_display(self, app):
        """Test that the detailed results table is displayed."""
        at = app.run()
        
        # Load example config and run analysis
        at = self.load_example_and_run_analysis(at)
        
        # Check for table headers
        table_headers = [header.value for header in at.subheader]
        assert any("ALMI Results Table" in header for header in table_headers), \
            "ALMI Results table section should be displayed"
        assert any("FFMI Results Table" in header for header in table_headers), \
            "FFMI Results table section should be displayed"
        
        # Verify data grid/table is present
        # Note: Streamlit's data_editor might not be directly accessible in AppTest
        # but we can check that no errors occurred and the section is present
        assert len(at.exception) == 0, "Table display should not cause exceptions"
    
    def test_form_validation(self, app):
        """Test that form validation works correctly."""
        at = app.run()
        
        # Try to run analysis without any data
        analysis_button = None
        for button in at.button:
            if "Run Analysis" in button.label:
                analysis_button = button
                break
        
        # Should not crash when no data is present
        if analysis_button:
            analysis_button.click()
            at = at.run()
            
            # Should handle gracefully (either with error message or no-op)
            # The main thing is no exceptions should occur
            assert len(at.exception) == 0, "Validation should handle empty forms gracefully"
    
    def test_csv_export_availability(self, app):
        """Test that CSV export functionality is available after analysis."""
        at = app.run()
        
        # Load example config and run analysis
        at = self.load_example_and_run_analysis(at)
        
        # Look for download button or CSV export functionality
        # This might be implemented as a download_button in Streamlit
        download_buttons = []
        for button in at.button:
            if "download" in button.label.lower() or "csv" in button.label.lower():
                download_buttons.append(button)
        
        # If CSV export is implemented, it should be available after analysis
        # If not implemented yet, this test serves as a reminder to add it
        # For now, we just verify no exceptions occurred during the process
        assert len(at.exception) == 0, "Analysis completion should enable export functionality"
    
    def test_fake_data_generation(self, app):
        """Test the fake data generation functionality."""
        at = app.run()
        
        # Look for and click the Random Profile button (button with ðŸŽ²)
        random_button = None
        for button in at.button:
            if "ðŸŽ² Random Profile" in button.label:
                random_button = button
                break
        
        if random_button:
            random_button.click()
            at = at.run()
            
            # Verify that fake data was generated (fields should be populated)
            birth_date_input = at.text_input[0]  # Birth date is first text input
            assert birth_date_input.value != "", "Birth date should be populated with fake data"
            
            # Verify no exceptions occurred during fake data generation
            assert len(at.exception) == 0, "Fake data generation should not cause exceptions"
    
    def test_plotly_goal_hover_formatting(self):
        """Test that goal hover text is properly formatted for plotly (unit test)."""
        # Test the underlying plotly function directly without streamlit
        from webapp import create_plotly_metric_plot
        from core import run_analysis_from_data, parse_gender, load_config_json, extract_data_from_config
        
        # Load example data to get realistic goal calculations
        try:
            config = load_config_json('example_config.json', quiet=True)
            user_info, scan_history, almi_goal, ffmi_goal = extract_data_from_config(config)
            user_info['gender_code'] = parse_gender(user_info['gender'])
            
            # Run analysis to get goal calculations
            df_results, goal_calculations, figures = run_analysis_from_data(
                user_info, scan_history, almi_goal, ffmi_goal
            )
            
            # Test ALMI goal hover if available
            if 'almi' in goal_calculations:
                from core import load_lms_data
                lms_functions = {}
                lms_functions['almi_L'], lms_functions['almi_M'], lms_functions['almi_S'] = load_lms_data('appendicular_LMI', user_info['gender_code'])
                lms_functions['lmi_L'], lms_functions['lmi_M'], lms_functions['lmi_S'] = load_lms_data('LMI', user_info['gender_code'])
                
                # Create plotly figure
                fig = create_plotly_metric_plot(df_results, 'ALMI', lms_functions, goal_calculations)
                
                # Find the goal trace
                goal_trace = None
                for trace in fig.data:
                    if trace.name == 'Goal':
                        goal_trace = trace
                        break
                
                # Verify goal trace exists and has proper hover formatting
                assert goal_trace is not None, "Goal trace should be present in plotly figure"
                assert hasattr(goal_trace, 'text'), "Goal trace should have text attribute for hover"
                # Plotly converts lists to tuples internally, so check for either
                assert isinstance(goal_trace.text, (list, tuple)), "Goal trace text should be a list or tuple for plotly compatibility"
                assert len(goal_trace.text) == 1, "Goal trace should have exactly one text item for single data point"
                
                # Verify hover content contains expected goal information
                hover_text = goal_trace.text[0]
                assert "ðŸŽ¯ ALMI Goal" in hover_text, "Hover should contain goal title"
                assert "Target Age:" in hover_text, "Hover should contain target age"
                assert "Target Body Composition:" in hover_text, "Hover should contain target body composition section"
                assert "Changes Needed:" in hover_text, "Hover should contain changes needed section"
                assert "Weight:" in hover_text, "Hover should contain weight information"
                assert "Lean Mass:" in hover_text, "Hover should contain lean mass information"
                
                print(f"âœ… Goal hover test passed! Hover text length: {len(hover_text)} chars")
                print(f"âœ… Text is properly formatted as list with {len(goal_trace.text)} item(s)")
                
        except FileNotFoundError:
            # If example config doesn't exist, create a minimal test
            print("âš ï¸ Example config not found, using minimal test data")
            import pandas as pd
            
            # Create minimal test data
            minimal_goal_calc = {
                'target_age': 45.0,
                'target_metric_value': 8.5,
                'target_percentile': 0.75,
                'target_z_score': 0.67,
                'target_body_composition': {
                    'weight_lbs': 170.0,
                    'lean_mass_lbs': 140.0,
                    'fat_mass_lbs': 30.0,
                    'body_fat_percentage': 17.6
                },
                'weight_change': 5.0,
                'lean_change': 3.0,
                'fat_change': 2.0,
                'bf_change': -1.0,
                'percentile_change': 15.0
            }
            
            goal_calculations = {'almi': minimal_goal_calc}
            df_results = pd.DataFrame({'date_str': ['2024-01-01'], 'age_at_scan': [44.0], 'almi_kg_m2': [8.0]})
            
            # Create simple LMS functions for testing
            lms_functions = {
                'almi_L': lambda x: 1.0,
                'almi_M': lambda x: 8.0,
                'almi_S': lambda x: 0.15,
                'lmi_L': lambda x: 1.0,
                'lmi_M': lambda x: 18.0,
                'lmi_S': lambda x: 0.12
            }
            
            # Test with minimal data
            fig = create_plotly_metric_plot(df_results, 'ALMI', lms_functions, goal_calculations)
            
            # Find goal trace and verify
            goal_trace = None
            for trace in fig.data:
                if trace.name == 'Goal':
                    goal_trace = trace
                    break
            
            assert goal_trace is not None, "Goal trace should be present even with minimal data"
            assert isinstance(goal_trace.text, (list, tuple)), "Goal trace text should be a list or tuple"
            assert len(goal_trace.text) == 1, "Goal trace should have one text item"
            
            print("âœ… Minimal goal hover test passed!")
            
        except Exception as e:
            pytest.fail(f"Goal hover test failed with exception: {e}")


class TestOptionalBFGoalIntegration:
    """Integration tests for optional body fat percentage goal functionality."""
    
    @pytest.fixture
    def app(self):
        """Create AppTest instance for the webapp."""
        return testing.AppTest.from_file("webapp.py", default_timeout=10)
    
    def setup_user_and_scan_data(self, at, bf_percentage=25.0, training_level="intermediate"):
        """Helper method to set up user info and scan data with specific BF%."""
        # Set user info
        birth_date_input = at.text_input[0]  # Birth date
        birth_date_input.set_value("04/26/1982")
        
        height_input = at.number_input[0]  # Height
        height_input.set_value(70.0)  # 70 inches
        
        gender_selectbox = at.selectbox[0]  # Gender
        gender_selectbox.set_value("male")
        
        # Set training level if available
        training_selectbox = None
        for selectbox in at.selectbox:
            if "training" in selectbox.label.lower():
                training_selectbox = selectbox
                break
        
        if training_selectbox:
            training_selectbox.set_value(training_level)
        
        at = at.run()
        
        # Add scan data with specific body fat percentage
        # Note: This is a simplified approach - actual implementation would
        # need to interact with the data editor component
        return at
    
    def test_optional_bf_athletic_range_maintains_current(self, app):
        """Test that athletic range BF% maintains current level."""
        at = app.run()
        
        # Load example config first to get basic structure
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        if load_button:
            load_button.click()
            at = at.run()
            
            # Clear any existing BF% goal (should be empty by default in new implementation)
            # The webapp should now have optional BF% inputs
            
            # Run analysis
            analysis_button = None
            for button in at.button:
                if "ðŸ”¬ Run Analysis" in button.label:
                    analysis_button = button
                    break
            
            if analysis_button:
                analysis_button.click()
                at = at.run()
                
                # Verify no exceptions occurred
                assert len(at.exception) == 0, "Analysis with optional BF% should not cause exceptions"
                
                # Check that goal information is displayed
                # The system should show goal information even without explicit BF% targets
                results_displayed = False
                for subheader in at.subheader:
                    if "Analysis Results" in subheader.value:
                        results_displayed = True
                        break
                
                assert results_displayed, "Analysis results should be displayed"
    
    def test_optional_bf_goal_message_display(self, app):
        """Test that goal messages display correctly with optional BF%."""
        at = app.run()
        
        # Load example config
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        if load_button:
            load_button.click()
            at = at.run()
            
            # Run analysis to generate goal messages
            analysis_button = None
            for button in at.button:
                if "ðŸ”¬ Run Analysis" in button.label:
                    analysis_button = button
                    break
            
            if analysis_button:
                analysis_button.click()
                at = at.run()
                
                # Verify analysis completed successfully
                assert len(at.exception) == 0, "Analysis should complete without errors"
                
                # The goal messages should now use the new dynamic format
                # Check that markdown/text content includes goal information
                goal_text_found = False
                for markdown in at.markdown:
                    if any(keyword in markdown.value.lower() for keyword in 
                           ['try to add', 'maintain', 'lean mass', 'body fat']):
                        goal_text_found = True
                        break
                
                # Goal information should be present in some form
                # (This is a basic check - actual message content would need manual verification)
                assert len(at.markdown) > 0, "Goal information should be displayed in markdown format"
    
    def test_optional_bf_with_empty_goal_fields(self, app):
        """Test behavior when BF% goal fields are explicitly empty."""
        at = app.run()
        
        # Load example config
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        if load_button:
            load_button.click()
            at = at.run()
            
            # Ensure BF% goal fields are empty (they should be by default now)
            # Find BF% number inputs if they exist
            bf_inputs = []
            for num_input in at.number_input:
                if "body fat" in num_input.label.lower() or "bf" in num_input.label.lower():
                    bf_inputs.append(num_input)
            
            # Clear any BF% inputs that might be populated
            for bf_input in bf_inputs:
                bf_input.set_value(None)  # Set to empty/None
            
            at = at.run()
            
            # Run analysis
            analysis_button = None
            for button in at.button:
                if "ðŸ”¬ Run Analysis" in button.label:
                    analysis_button = button
                    break
            
            if analysis_button:
                analysis_button.click()
                at = at.run()
                
                # Should handle empty BF% goals gracefully
                assert len(at.exception) == 0, "Empty BF% goals should be handled gracefully"
                
                # Analysis should still complete and show results
                metrics_displayed = len(at.metric) > 0
                assert metrics_displayed, "Metrics should still be displayed with optional BF%"
    
    def test_webapp_bf_goal_forms_present(self, app):
        """Test that the new optional BF% goal input fields are present."""
        at = app.run()
        
        # Check that BF% goal inputs are available in the goals section
        bf_goal_inputs_found = 0
        for num_input in at.number_input:
            if "body fat" in num_input.label.lower() and "optional" in num_input.label.lower():
                bf_goal_inputs_found += 1
        
        # Should have BF% inputs for both ALMI and FFMI goals
        # Note: This assumes the new optional BF% inputs have been added to the webapp
        assert bf_goal_inputs_found >= 0, "Optional BF% goal inputs should be present in goals section"
        
        # Verify help text mentions intelligent targeting
        help_text_found = False
        for num_input in at.number_input:
            if ("body fat" in num_input.label.lower() and 
                num_input.help and 
                "intelligent" in num_input.help.lower()):
                help_text_found = True
                break
        
        # The help text should explain the intelligent targeting feature
        # This verifies the UI communicates the new functionality to users
    
    def test_optional_bf_different_health_categories(self, app):
        """Test optional BF% targeting for different health categories."""
        at = app.run()
        
        # Load example config to get baseline
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        if load_button:
            load_button.click()
            at = at.run()
            
            # Run analysis to see how the system handles the example data
            analysis_button = None
            for button in at.button:
                if "ðŸ”¬ Run Analysis" in button.label:
                    analysis_button = button
                    break
            
            if analysis_button:
                analysis_button.click()
                at = at.run()
                
                # Verify the system handles different BF% categories
                # The example config has BF% values that should trigger different logic
                assert len(at.exception) == 0, "Different BF% health categories should be handled correctly"
                
                # Check that goal messages are displayed
                markdown_content = [md.value for md in at.markdown if md.value]
                goal_messages_present = any(
                    any(keyword in content.lower() for keyword in ['maintain', 'add', 'target', 'body fat'])
                    for content in markdown_content
                )
                
                # Goal information should be present somewhere in the output
                assert len(markdown_content) > 0, "Goal-related content should be displayed"
    
    def test_optional_bf_training_level_impact(self, app):
        """Test that training level affects BF% targeting feasibility."""
        at = app.run()
        
        # Load example config
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        if load_button:
            load_button.click()
            at = at.run()
            
            # Set different training levels to see if it affects calculations
            training_selectbox = None
            for selectbox in at.selectbox:
                if "training" in selectbox.label.lower():
                    training_selectbox = selectbox
                    break
            
            if training_selectbox:
                # Test with advanced training level
                training_selectbox.set_value("advanced")
                at = at.run()
                
                # Run analysis
                analysis_button = None
                for button in at.button:
                    if "ðŸ”¬ Run Analysis" in button.label:
                        analysis_button = button
                        break
                
                if analysis_button:
                    analysis_button.click()
                    at = at.run()
                    
                    # Advanced training level should still work with optional BF%
                    assert len(at.exception) == 0, "Advanced training level should work with optional BF%"
    
    def test_optional_bf_backward_compatibility(self, app):
        """Test that the system maintains backward compatibility with explicit BF% goals."""
        at = app.run()
        
        # Load example config
        load_button = None
        for button in at.button:
            if "ðŸ“‹ Load Example" in button.label:
                load_button = button
                break
        
        if load_button:
            load_button.click()
            at = at.run()
            
            # If BF% goal inputs exist, set explicit values
            bf_inputs = []
            for num_input in at.number_input:
                if "body fat" in num_input.label.lower() and "optional" in num_input.label.lower():
                    bf_inputs.append(num_input)
            
            # Set explicit BF% values if inputs are available
            for i, bf_input in enumerate(bf_inputs[:2]):  # Limit to first 2 (ALMI, FFMI)
                bf_input.set_value(15.0)  # Set to 15% body fat
            
            at = at.run()
            
            # Run analysis
            analysis_button = None
            for button in at.button:
                if "ðŸ”¬ Run Analysis" in button.label:
                    analysis_button = button
                    break
            
            if analysis_button:
                analysis_button.click()
                at = at.run()
                
                # Should work with explicit BF% values (backward compatibility)
                assert len(at.exception) == 0, "Explicit BF% goals should still work (backward compatibility)"


class TestWebAppErrorHandling:
    """Test error handling scenarios in the webapp."""
    
    @pytest.fixture
    def app(self):
        """Create AppTest instance for the webapp."""
        return testing.AppTest.from_file("webapp.py", default_timeout=10)
    
    def test_invalid_date_handling(self, app):
        """Test handling of invalid date inputs."""
        at = app.run()
        
        # Try to enter invalid date in birth date input (index 0)
        birth_date_input = at.text_input[0]
        birth_date_input.input("invalid-date")
        at = at.run()
        
        # Should handle gracefully without crashing
        assert len(at.exception) == 0, "Invalid date should be handled gracefully"
    
    def test_missing_required_fields(self, app):
        """Test handling when required fields are missing."""
        at = app.run()
        
        # Set only partial data - use selectbox for gender (index 0)
        gender_selectbox = at.selectbox[0]
        gender_selectbox.set_value("male")
        at = at.run()
        
        # Try to run analysis
        analysis_button = None
        for button in at.button:
            if "ðŸ”¬ Run Analysis" in button.label:
                analysis_button = button
                break
        
        if analysis_button:
            analysis_button.click()
            at = at.run()
            
            # Should handle missing data gracefully
            assert len(at.exception) == 0, "Missing required fields should be handled gracefully"


def run_integration_tests():
    """Run all integration tests programmatically."""
    import subprocess
    import sys
    
    try:
        result = subprocess.run([
            sys.executable, "-m", "pytest", 
            "test_webapp_integration.py", 
            "-v", "--tb=short"
        ], capture_output=True, text=True, cwd=Path(__file__).parent)
        
        print("INTEGRATION TEST RESULTS:")
        print("=" * 50)
        print(result.stdout)
        if result.stderr:
            print("STDERR:")
            print(result.stderr)
        
        return result.returncode == 0
        
    except Exception as e:
        print(f"Error running tests: {e}")
        return False


if __name__ == "__main__":
    # Allow running tests directly
    success = run_integration_tests()
    exit(0 if success else 1)